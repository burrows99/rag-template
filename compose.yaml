networks:
  elastic-net:
    name: elastic-net
    driver: bridge

services:
  # Elasticsearch: Vector database and search engine for retrieval agent
  # Source: https://github.com/langchain-ai/retrieval-agent-template
  # Official docs: https://www.elastic.co/guide/en/elasticsearch/reference/current/run-elasticsearch-locally.html
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.1
    container_name: elasticsearch
    ports:
      # Bind to localhost only for security - prevents external access
      - "127.0.0.1:9200:9200"
    environment:
      # Default password for development (NEVER use in production)
      - ELASTIC_PASSWORD=changeme
      # Single-node mode: Suitable for local development, not for production clusters
      - discovery.type=single-node
      # Disable SSL: Simplifies local development (MUST enable for production)
      - xpack.security.http.ssl.enabled=false
      # Trial license: Enables all features for testing (14-day trial)
      - xpack.license.self_generated.type=trial
      # JVM heap size: 512MB min/max - balances performance with memory usage
      # Recommendation: Set to 50% of available RAM, max 32GB in production
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      # Persist index data between container restarts
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - elastic-net
    restart: unless-stopped
    # Memory limit: Prevents Elasticsearch from consuming excessive RAM
    # Must be higher than JVM heap (512MB * 2 = 1GB minimum)
    mem_limit: 1g

  # Cognee: AI knowledge graph system for semantic memory and retrieval
  # Official docs: https://github.com/topoteretes/cognee
  cognee:
    image: cognee/cognee:main
    container_name: cognee
    ports:
      - "8000:8000"
    volumes:
      # Persist all Cognee data (SQLite, LanceDB, Kuzu graph DB) to host
      - ./cognee/data:/root/.cognee
    env_file:
      - .env.cognee
    networks:
      - elastic-net
    restart: unless-stopped

  # Cognee MCP Server: Model Context Protocol interface for VS Code integration
  # Enables Cognee tools via MCP: cognify, search, prune, etc.
  cognee-mcp:
    image: cognee/cognee-mcp:main
    container_name: cognee-mcp
    ports:
      - "8001:8000"
    environment:
      # SSE transport: Server-Sent Events for real-time MCP communication
      - TRANSPORT_MODE=sse
      # Internal Docker network URL (not localhost from container perspective)
      - API_URL=http://cognee:8000
    networks:
      - elastic-net
    depends_on:
      - cognee
    restart: unless-stopped

  # LangGraph Server: Python-based retrieval agent with indexing and query graphs
  # Source: https://github.com/langchain-ai/langgraph
  # Docs: https://docs.langchain.com/oss/python/langgraph/overview
  # Self-hosted deployment: https://docs.langchain.com/langsmith/self-hosted
  langgraph-server:
    build:
      context: ./retrieval-agent
      dockerfile: Dockerfile
    container_name: langgraph-server
    ports:
      # LangGraph API server port
      - "2024:2024"
    environment:
      # Load all environment variables from .env.retrieval-agent
      # Includes: OPENAI_API_KEY, ANTHROPIC_API_KEY, retriever configs, etc.
      - PORT=2024
    env_file:
      - .env.retrieval-agent
    command: ["langgraph", "dev", "--port", "2024", "--host", "0.0.0.0"]
    extra_hosts:
      # Enable container to reach host machine's Ollama Desktop app
      - "host.docker.internal:host-gateway"
    networks:
      - elastic-net
    restart: unless-stopped
    depends_on:
      - cognee
      - elasticsearch
    # Note: LangGraph requires Python runtime with langgraph CLI
    # Install in container: pip install langgraph-cli

  # Next.js Chat UI: Frontend interface for LangGraph retrieval agent
  # Source: https://github.com/langchain-ai/agent-chat-ui
  # Deployment: https://nextjs.org/docs/app/getting-started/deploying#docker
  agent-chat-ui:
    build:
      context: ./agent-chat-ui
      dockerfile: Dockerfile
    container_name: agent-chat-ui
    ports:
      # Next.js application port
      - "3000:3000"
    environment:
      # Point to LangGraph server via Docker network
      # Override for container-to-container communication
      - NEXT_PUBLIC_API_URL=http://langgraph-server:2024
      - NODE_ENV=production
    env_file:
      # Load configuration from .env.agent-chat-ui
      # Includes: NEXT_PUBLIC_ASSISTANT_ID, LANGSMITH_API_KEY
      - .env.agent-chat-ui
    networks:
      - elastic-net
    restart: unless-stopped
    depends_on:
      - langgraph-server
  # Note: Uses Next.js standalone output mode for minimal Docker image
  # Ref: https://nextjs.org/docs/app/api-reference/config/next-config-js/output

  # Azure SQL Server: Microsoft SQL database for document loading via SQLDatabaseLoader
  # Source: LangChain SQLDatabaseLoader for structured data ingestion
  # Official docs: https://learn.microsoft.com/sql/linux/quickstart-install-connect-docker
  azure-sql-server:
    image: mcr.microsoft.com/mssql/server:2022-latest
    container_name: azure-sql-server
    ports:
      # Bind to localhost only for security - prevents external access
      - "127.0.0.1:1433:1433"
    environment:
      # Accept EULA: Required to use SQL Server (read EULA before production use)
      - ACCEPT_EULA=Y
      # SA password: Loaded from environment variable for security
      # Requirements: 8+ chars, uppercase, lowercase, digits, special chars
      - MSSQL_SA_PASSWORD=${MSSQL_SA_PASSWORD:-YourStrong@Passw0rd}
      # Product ID: Developer edition (free, full-featured for non-production)
      # Options: Developer, Express (free), Standard, Enterprise (licensed)
      - MSSQL_PID=Developer
    volumes:
      # Persist database files (.mdf, .ndf) between container restarts
      - ./azure-sql-server/data:/var/opt/mssql/data
      # Persist transaction logs (.ldf) for point-in-time recovery
      - ./azure-sql-server/log:/var/opt/mssql/log
      # Persist certificates and encryption keys
      - ./azure-sql-server/secrets:/var/opt/mssql/secrets
    healthcheck:
      test: ["CMD", "/opt/mssql-tools18/bin/sqlcmd", "-S", "localhost", "-U", "sa", "-P", "${MSSQL_SA_PASSWORD:-YourStrong@Passw0rd}", "-C", "-Q", "SELECT 1"]
      interval: 10s
      timeout: 3s
      retries: 10
      start_period: 10s
    networks:
      - elastic-net
    restart: unless-stopped

  # MinIO: S3-compatible object storage for document files (PDFs, DOCX, TXT, etc.)
  # Source: LangChain S3DirectoryLoader with MinIO endpoint for file ingestion
  # Official docs: https://min.io/docs/minio/container/index.html
  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      # Bind to localhost only for security - prevents external access
      # Port 9000: S3 API endpoint (boto3, AWS CLI compatible)
      - "127.0.0.1:9000:9000"
      # Port 9001: Web Console UI for bucket management
      - "127.0.0.1:9001:9001"
    environment:
      # Root credentials: Loaded from environment variables for security
      # Use strong passwords and consider IAM policies for production
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minioadmin}
    volumes:
      # Persist object storage data (all uploaded files) between container restarts
      - ./minio/data:/data
    command: ["server", "/data", "--console-address", ":9001"]
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - elastic-net
    restart: unless-stopped

  # Adminer: Database management tool for Azure SQL Server
  # Source: https://www.adminer.org/
  # Official docs: https://hub.docker.com/_/adminer
  adminer:
    image: adminer:latest
    container_name: adminer
    ports:
      # Bind to localhost only for security - prevents external access
      # Port 8080: Web UI for database management
      - "127.0.0.1:8080:8080"
    environment:
      # Default to SQL Server driver
      - ADMINER_DEFAULT_SERVER=azure-sql-server
    networks:
      - elastic-net
    restart: unless-stopped
    depends_on:
      - azure-sql-server

volumes:
  elasticsearch-data: