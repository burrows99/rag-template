# Docker Compose Build Optimization
# Source: https://docs.docker.com/build/bake/compose-file/
# Enables Bake delegation for faster, parallel builds (v5.0.0+)
COMPOSE_BAKE=true

# To separate your traces from other application
LANGSMITH_PROJECT=retrieval-agent

# The following depend on your selected configuration

# LLM Model Configuration
# Specify models for response generation and query refinement
# Format: provider/model-name
# RESPONSE_MODEL=anthropic/claude-3-5-sonnet-20240620
# QUERY_MODEL=anthropic/claude-3-haiku-20240307
# EMBEDDING_MODEL=openai/text-embedding-3-small

# LLM Provider API Keys:
ANTHROPIC_API_KEY=....
FIREWORKS_API_KEY=...
OPENAI_API_KEY=...

# Ollama (local LLM server)
OLLAMA_BASE_URL=http://host.docker.internal:11434
# Example models for Ollama:
RESPONSE_MODEL=ollama/gpt-oss:120b-cloud
QUERY_MODEL=ollama/gpt-oss:120b-cloud
EMBEDDING_MODEL=ollama/nomic-embed-text:latest

# Retrieval provider

## Elastic cloud:
ELASTICSEARCH_URL=...
ELASTICSEARCH_API_KEY=...

## Elastic local:
ELASTICSEARCH_URL=http://elasticsearch:9200
ELASTICSEARCH_USER=elastic
ELASTICSEARCH_PASSWORD=changeme

## Pinecone
PINECONE_API_KEY=...
PINECONE_INDEX_NAME=...

## Mongo Atlas
MONGODB_URI=... # Full connection string

## Cognee
COGNEE_API_URL=http://cognee:8000

# Data Source Configuration (for load_docs node)

## MinIO (S3-compatible object storage)
MINIO_ENDPOINT_URL=http://host.docker.internal:9000
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin

## Azure SQL Server
MSSQL_SERVER=host.docker.internal
MSSQL_PORT=1433
MSSQL_DATABASE=master
MSSQL_USER=sa
MSSQL_SA_PASSWORD=YourStrong@Passw0rd